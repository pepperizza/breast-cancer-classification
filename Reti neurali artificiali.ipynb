{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\",\n",
    "                           names=[\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"])\n",
    "\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.drop(['id','diagnosis'], axis=1).values\n",
    "Y = breast_cancer['diagnosis'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifichiamo i label della nostra variabile target in numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizziamo gli array con le features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape                   #398 esempi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo il modello di rete neurale con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()                                    #la rete avrà un unico strato nascosto con 12 nodi all'interno\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))  #12 nodi nello strato nascosto, numero di nodi dello strato di partenza(features), funz att\n",
    "model.add(Dense(1, activation='sigmoid'))                            #1 neurone per l'output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])          #per addestrare il modello stochastic gradiant descend\n",
    "model.summary()         #per vedere un sommario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4782 - loss: 0.8523  \n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6513 - loss: 0.6883 \n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7541 - loss: 0.5947 \n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4941 \n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.4443 \n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9022 - loss: 0.4032 \n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.3665 \n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.3354 \n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.3024 \n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2991 \n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.2542 \n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.2658 \n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.2388 \n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.2221 \n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.2009 \n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.2082 \n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1817 \n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1906 \n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1805 \n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.1642 \n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1629 \n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9411 - loss: 0.1944 \n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1470 \n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.1616 \n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1450 \n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1471 \n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9578 - loss: 0.1448 \n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1523 \n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.1307 \n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1406 \n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1321 \n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.1341 \n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1455 \n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.1177 \n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1186 \n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1296 \n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1281 \n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.1080 \n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9603 - loss: 0.1231 \n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1163 \n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.1123 \n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1310 \n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1303 \n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.1102 \n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1154 \n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0937 \n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1272 \n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9726 - loss: 0.1032 \n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.1067 \n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1072 \n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0929 \n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.1098 \n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1067 \n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1185 \n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0934 \n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1200 \n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.1020 \n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0903 \n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1090 \n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1076 \n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.1083 \n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0931 \n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1038 \n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1100 \n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1093 \n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0865 \n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1062 \n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0940 \n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0873 \n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0970 \n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0880 \n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1050 \n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0883 \n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0979 \n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.1141 \n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0913 \n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0858 \n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0976 \n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0907 \n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1239 \n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0913 \n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.0972 \n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9812 - loss: 0.0777 \n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.1022 \n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0901 \n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0760 \n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0875 \n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0673 \n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0894 \n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0634 \n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.1077 \n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0697 \n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0885 \n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0764 \n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0891 \n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.0969 \n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0969 \n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0898 \n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0900 \n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x280fc6d50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)         #avvio l'addestramento per 100 epoche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo questi risultati sul test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1057 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11000386625528336, 0.9415204524993896]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "#funzione di costo più bassa rispetto al caso di una regressione logistica e questo porta a performance migliori perchè avere una loss minore\n",
    "#vuol dire avere un'incertezza minore sul test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proviamo una rete neurale artificiale profonda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()                                    \n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))  \n",
    "model.add(Dense(4, activation='relu'))                      #aggiungo uno strato nascosto denso\n",
    "model.add(Dense(1, activation='sigmoid'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m52\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> (1.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m429\u001b[0m (1.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> (1.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m429\u001b[0m (1.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])          #per addestrare il modello stochastic gradiant descend\n",
    "model.summary()         #per vedere un sommario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3884 - loss: 0.7419  \n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4605 - loss: 0.7211 \n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: 0.6629 \n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.6463 \n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.6265 \n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.6138 \n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5797 \n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.5819 \n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8455 - loss: 0.5675 \n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.5458 \n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.5318 \n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8750 - loss: 0.5236 \n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.5166 \n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.4949 \n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.4834 \n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.4735 \n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.4739 \n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.4665 \n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.4425 \n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.4426 \n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.4268 \n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.4189 \n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.4264 \n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.4128 \n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.3927 \n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.3923 \n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.3640 \n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.3874 \n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.3582 \n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.3473 \n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.3532 \n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.3562 \n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.3517 \n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.3403 \n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.3500 \n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.3416 \n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.3227 \n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.3355 \n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.3255 \n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.3063 \n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.3074 \n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.2997 \n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.3139 \n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.2865 \n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.2915 \n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9518 - loss: 0.2922 \n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2988 \n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.2851 \n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.2777 \n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.2553 \n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.2622 \n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.2548 \n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.2704 \n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9656 - loss: 0.2586 \n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.2545 \n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.2517 \n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.2479 \n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.2441 \n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.2429 \n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9564 - loss: 0.2483 \n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.2390 \n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.2334 \n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.2402 \n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.2216 \n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.2373 \n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.2106 \n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.2263 \n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.2162 \n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.1997 \n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.2045 \n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.2135 \n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.1918 \n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.2075 \n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.1915 \n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.1815 \n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.1954 \n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.1827 \n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.1843 \n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1815 \n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.1704 \n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.1613 \n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9741 - loss: 0.1661 \n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1788 \n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1783 \n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1708 \n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1720 \n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.1507 \n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.1533 \n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1533 \n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1527 \n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.1414 \n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9645 - loss: 0.1454 \n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.1350 \n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.1324 \n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.1376 \n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9732 - loss: 0.1266 \n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9821 - loss: 0.1130 \n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.1272 \n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.1344 \n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.1218 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x284064380>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)         #avvio l'addestramento per 100 epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.1407 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1634223610162735, 0.9532163739204407]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)                  #performa meglio rispetto ad un solo strato nascosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizzare la leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "model = Sequential()                                    \n",
    "model.add(Dense(12, input_dim=X_train.shape[1]))        #rimuovo le funzioni di attivazione, quindi sarà lineare\n",
    "model.add(LeakyReLU(alpha=0.01))            #strato nascosto in più con leakyrelu, alpha valore di moltiplicazione di z (net input) quando vale meno di 0\n",
    "model.add(Dense(4))        \n",
    "model.add(LeakyReLU(alpha=0.01))            #lo aggiungo anche dopo il secondo strato nascosto                         \n",
    "model.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m52\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> (1.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m429\u001b[0m (1.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> (1.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m429\u001b[0m (1.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])          #per addestrare il modello con stochastic gradiant descend\n",
    "model.summary()         #per vedere un sommario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La leaky relu prende lo stato lineare dello strato nascosto precedente e applica una trasformazione non lineare per poi passarlo allo strato successivo\n",
    "Il numero dei parametri non cambia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4408 - loss: 0.7293  \n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.6389 \n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6601 - loss: 0.5779 \n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5277 \n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7717 - loss: 0.4721 \n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.4473 \n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.4145 \n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.3783 \n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.3300 \n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.3048 \n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.3051 \n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.2566 \n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.2644 \n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.2436 \n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.2368 \n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.2391 \n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.2075 \n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1876 \n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.2259 \n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.2046 \n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1950 \n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2083 \n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1693 \n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.1451 \n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1607 \n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1389 \n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.1355 \n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1778 \n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1669 \n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1601 \n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.1601 \n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1322 \n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.1293 \n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9638 - loss: 0.1189 \n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1098 \n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1214 \n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1053 \n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1431 \n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1281 \n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1211 \n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1240 \n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1221 \n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1160 \n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1184 \n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9603 - loss: 0.1055 \n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1116 \n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.1035 \n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1218 \n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1027 \n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.1094 \n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.0873 \n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0972 \n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0841 \n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1118 \n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1123 \n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0823 \n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.0875 \n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0841 \n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0864 \n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.1032 \n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.0868 \n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.0912 \n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.0980 \n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0883 \n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0845 \n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0982 \n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0960 \n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9787 - loss: 0.0723 \n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0996 \n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0807 \n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0892 \n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0688 \n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0830 \n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0688 \n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0878 \n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.0799 \n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0711 \n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0823 \n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0704 \n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0821 \n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0782 \n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0693 \n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9764 - loss: 0.0628 \n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9719 - loss: 0.0750 \n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0904 \n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9738 - loss: 0.0738 \n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9695 - loss: 0.0783 \n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0648 \n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0645 \n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9754 - loss: 0.0684 \n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0561 \n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.0672 \n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9806 - loss: 0.0614 \n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0770 \n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9763 - loss: 0.0689 \n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.0723 \n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9820 - loss: 0.0657 \n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9739 - loss: 0.0736 \n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0614 \n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.0786 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x284de4d70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)         #avvio l'addestramento per 100 epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0712 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08526071906089783, 0.9707602262496948]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)                      #risultati buoni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nel caso di diagnosi mediche la classificazione di un caso positivo con uno negativo è più grave del suo contrario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usare la matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[107,   1],\n",
       "       [  4,  59]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")      #dobbiamo predire le classi, assicurandoci che siano interi compresi tra 0 e 1\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizzo una funzione per plottare la matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, ['benigno', 'maligno'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
